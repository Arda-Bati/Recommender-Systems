{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        yield eval(l)\n",
    "\n",
    "def readCSV(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        yield l.strip().split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "example = readCSV(\"train_Interactions.csv.gz\")\n",
    "print(next(example))\n",
    "del example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Would-read baseline: just rank which books are \n",
    "### popular and which are not, and return '1' if a\n",
    "### book is among the top-ranked\n",
    "train_size = 170000\n",
    "\n",
    "data = [line for line in readCSV(\"train_Interactions.csv.gz\")]\n",
    "random.shuffle(data)\n",
    "train = data[:train_size]\n",
    "val   = data[train_size:]\n",
    "print(len(data))\n",
    "print(len(train))\n",
    "print(len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booksReadBy = defaultdict(set)\n",
    "all_books = set()\n",
    "\n",
    "for user, book, _ in val:\n",
    "    all_books.add(book)\n",
    "    booksReadBy[user].add(book)\n",
    "\n",
    "val_unread = []\n",
    "all_books_count = len(all_books)\n",
    "for user, book, _ in val: \n",
    "    unread_book = random.sample(all_books, 1)\n",
    "    while(unread_book in list(booksReadBy[user])):\n",
    "        unread_book = random.sample(all_books, 1)\n",
    "    val_unread.append([user, str(unread_book[0]), '-1'])\n",
    "\n",
    "val = val + val_unread\n",
    "print(len(val))\n",
    "print(val[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookCount = defaultdict(int)\n",
    "total_books_read = 0\n",
    "\n",
    "for user, book, _ in train:\n",
    "    bookCount[book]  += 1\n",
    "    total_books_read += 1\n",
    "\n",
    "mostPopular = [(bookCount[book], book) for book in bookCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def popular_books_set(mostPopular, threshold_ratio):\n",
    "    return1 = set()\n",
    "    cur_book_count = 0\n",
    "    for book_count, book in mostPopular:\n",
    "        cur_book_count += book_count\n",
    "        return1.add(book)\n",
    "        if cur_book_count > total_books_read *\\\n",
    "        threshold_ratio: \n",
    "            break\n",
    "    return return1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balanced Error Rate function\n",
    "def balanced_error_rate(pred, labels):\n",
    "    TP_ = np.logical_and(pred, labels)\n",
    "    FP_ = np.logical_and(pred, np.logical_not(labels))\n",
    "    TN_ = np.logical_and(np.logical_not(pred), np.logical_not(labels))\n",
    "    FN_ = np.logical_and(np.logical_not(pred), labels)\n",
    "\n",
    "    TP = sum(TP_)\n",
    "    FP = sum(FP_)\n",
    "    TN = sum(TN_)\n",
    "    FN = sum(FN_)\n",
    "    \n",
    "    acc = (TP + TN) / (TP + FP + TN + FN)\n",
    "    BER = 1 - 0.5 * (TP / (TP + FN) + TN / (TN + FP))\n",
    "    return acc, BER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return1 = popular_books_set(mostPopular, threshold_ratio = 0.5)\n",
    "predictions = []\n",
    "for data_point in val:\n",
    "    user, book, _ = data_point\n",
    "    prediction = book in return1\n",
    "    predictions.append(prediction)\n",
    "\n",
    "labels = [int(rating) >= 0 for _, _, rating in val]\n",
    "predictions = np.array(predictions)\n",
    "labels      = np.array(labels)\n",
    "acc, BER = balanced_error_rate(predictions, labels)\n",
    "print('Accuracy on validation set is:', acc)\n",
    "print('BER on validation set is:', BER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "BERs = []\n",
    "ratio_count = 50\n",
    "threshold_ratios = np.linspace(0.01, 1, ratio_count)\n",
    "\n",
    "# pops = np.linspace(0.2, 0.6, 20)\n",
    "loop_count = 0\n",
    "for ratio in threshold_ratios:\n",
    "    loop_count += 1\n",
    "    if loop_count % 10 == 0: print(loop_count, end = ' ')\n",
    "    return1 = popular_books_set(mostPopular, ratio)\n",
    "    predictions = []\n",
    "    for data_point in val:\n",
    "        user, book, _ = data_point\n",
    "        prediction = book in return1\n",
    "        predictions.append(prediction)\n",
    "\n",
    "    labels = [int(rating) >= 0 for _, _, rating in val]\n",
    "    predictions = np.array(predictions)\n",
    "    labels      = np.array(labels)\n",
    "    acc, BER = balanced_error_rate(predictions, labels)\n",
    "    accuracies.append(acc); BERs.append(BER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(threshold_ratios, accuracies, label='Validation acc')\n",
    "plt.plot(threshold_ratios, BERs, label='Validation BER')\n",
    "plt.ylabel('validation acc & BER')\n",
    "plt.xlabel('threshold popularity')\n",
    "plt.title('Validation acc & BER vs threshold popularity')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indx1 = accuracies.index(max(accuracies))\n",
    "print('Ratio with best accuracy is:', threshold_ratios[indx1])\n",
    "indx2 = BERs.index(min(BERs))\n",
    "print('Ratio with best BER is:', threshold_ratios[indx2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the curve above, it seems whatever value I find for the threshold, it will be very close to 0.5. I tried different granularities for the ratios, but the best values I got were always very close to 0.5. It seems for this validtion set, the ideal value is 0.5 and there might be fluctuations around it.\n",
    "\n",
    "I think this is related to the balance of the validation set. If I shift the balance, for example if I have 10000 positive 5000 negative examples, higher thresholds always lead to higher validation accuracy. For 5000 positive 10000 negative examples, lower thresholds always lead to better validtion accuracy. For 10000 positive 10000 negative (balanced), I get the graph above, which peaks at 0.5 popularity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(set1, set2):\n",
    "    \"\"\"\n",
    "    Returns the Jaccard similarity between two sets,\n",
    "    set1 & set2\n",
    "    \"\"\"\n",
    "    set_intersection = len(set1.intersection(set2))\n",
    "    set_union = len(set1.union(set2))\n",
    "    if set_union == 0:\n",
    "        print(set1, set2)\n",
    "        return 0\n",
    "    else:\n",
    "        return set_intersection / set_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_prediction(jac_sims):\n",
    "    \"\"\"\n",
    "    Returns the Jaccard similarity between two sets,\n",
    "    set1 & set2\n",
    "    \"\"\"\n",
    "    prediction = False\n",
    "    if jac_sims != []:\n",
    "        prediction = max(jac_sims) >= jaccard_threshold\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booksReadBy   = defaultdict(set)\n",
    "usersReadBook = defaultdict(set)\n",
    "\n",
    "for user, book, _ in train:\n",
    "    val_all_books.add(book)\n",
    "    booksReadBy[user].add(book)\n",
    "\n",
    "for user, book, _ in train:\n",
    "    usersReadBook[book].add(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.linspace(0.001, 0.1, 50)\n",
    "accuracies = []\n",
    "BERs = []\n",
    "loop_count = 0\n",
    "return1 = popular_books_set(mostPopular, threshold_ratios[indx2])\n",
    "for jaccard_threshold in thresholds:\n",
    "    loop_count += 1\n",
    "    if loop_count % 10 == 0: print(loop_count, end = ' ')\n",
    "    predictions = []\n",
    "    for user, book_predict, _ in val:\n",
    "        books_user_read = booksReadBy[user]\n",
    "        jac_sims = []\n",
    "        for users_book in books_user_read:   \n",
    "            users_read_book_predict = usersReadBook[book_predict]\n",
    "            users_read_users_book = usersReadBook[users_book]\n",
    "            jac_sim = jaccard(users_read_book_predict, users_read_users_book)\n",
    "            jac_sims.append(jac_sim)\n",
    "        prediction = jaccard_prediction(jac_sims)\n",
    "        predictions.append(prediction)\n",
    "\n",
    "    predictions = np.array(predictions)\n",
    "    acc, BER = balanced_error_rate(predictions, labels)\n",
    "    accuracies.append(acc); BERs.append(BER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(thresholds, accuracies, label='Validation acc')\n",
    "plt.plot(thresholds, BERs, label='Validation BER')\n",
    "plt.ylabel('validation acc & BER')\n",
    "plt.xlabel('Jaccard Threshold')\n",
    "plt.title('Validation acc & BER vs Jaccard Threshold')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indx = accuracies.index(max(accuracies))\n",
    "print('Jaccard threshold with best accuracy is:',\\\n",
    "      thresholds[indx])\n",
    "print('This threshold has validation accuracy:',\\\n",
    "      accuracies[indx])\n",
    "\n",
    "indx = BERs.index(min(BERs))\n",
    "print('Jaccard threshold with best BER is:',\\\n",
    "      thresholds[indx])\n",
    "print('This threshold has validation BER:',\\\n",
    "      BERs[indx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_jac(user, book_predict):\n",
    "    books_user_read = booksReadBy[user]\n",
    "    jac_sims = []\n",
    "    for users_book in books_user_read:   \n",
    "        users_read_book_predict = usersReadBook[book_predict]\n",
    "        users_read_users_book = usersReadBook[users_book]\n",
    "        jac_sim = jaccard(users_read_book_predict, users_read_users_book)\n",
    "        jac_sims.append(jac_sim)\n",
    "    return jac_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = 50\n",
    "pops = np.linspace(0.2, 0.7, sizes)\n",
    "jaccards = np.linspace(0.01, 0.03, sizes)\n",
    "print(len(pops))\n",
    "print(len(jaccards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_accuracies = []\n",
    "all_BERs = []\n",
    "loop_count = 0\n",
    "max_acc = 0\n",
    "for pop_threshold in pops:\n",
    "    accuracies = []; BERs = []\n",
    "    return1 = popular_books_set(mostPopular, pop_threshold)\n",
    "    for jaccard_threshold in jaccards:\n",
    "        loop_count += 1\n",
    "        if loop_count % 10 == 0: print(loop_count, end = ' ')\n",
    "        predictions = []\n",
    "        for user, book_predict, _ in val:\n",
    "                books_user_read = booksReadBy[user]\n",
    "                jac_sims = calc_jac(user, book_predict)\n",
    "                prediction_jac = jaccard_prediction(jac_sims)\n",
    "                prediction_pop = book_predict in return1\n",
    "                prediction = prediction_jac or prediction_pop          \n",
    "                predictions.append(prediction)\n",
    "        predictions = np.array(predictions)\n",
    "        acc, BER = balanced_error_rate(predictions, labels)\n",
    "        accuracies.append(acc), BERs.append(BER) \n",
    "    all_accuracies.append(accuracies); all_BERs.append(BERs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accs = [max(acc) for acc in all_accuracies]\n",
    "indx1 = best_accs.index(max(best_accs))\n",
    "print('Population threshold with best accuracy is:',\\\n",
    "      pops[indx1])\n",
    "best_jaccards = all_accuracies[indx1]\n",
    "indx2 = best_jaccards.index(max(best_jaccards))\n",
    "print('Jaccard threshold with best accuracy:',\\\n",
    "      jaccards[indx2])\n",
    "print('Best accuracy', all_accuracies[indx1][indx2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_BERs = [min(acc) for acc in all_BERs]\n",
    "indx1 = best_BERs.index(min(best_BERs))\n",
    "print('Population threshold with best BER is:',\\\n",
    "      pops[indx1])\n",
    "best_jaccards = all_BERs[indx1]\n",
    "indx2 = best_jaccards.index(min(best_jaccards))\n",
    "print('Jaccard threshold with best BER:',\\\n",
    "      jaccards[indx2])\n",
    "print('Best BER', all_BERs[indx1][indx2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I find the best results (out of the ones I tried) to be as shown above (for the validation set)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My username on Kaggle is: Arda Cankat Bati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_datapoint(user, book_predict):\n",
    "    books_user_read = booksReadBy[user]\n",
    "    jac_sims = calc_jac(user, book_predict)\n",
    "    prediction_jac = max(jac_sims) >= jaccard_threshold\n",
    "    prediction_pop = book_predict in return1\n",
    "    prediction = prediction_jac or prediction_pop          \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_threshold = 0.021\n",
    "pop_threshold = 0.42\n",
    "return1 = popular_books_set(mostPopular, pop_threshold)\n",
    "\n",
    "with open(\"predictions_Read.txt\", 'w') as predictions:\n",
    "    for l in open(\"pairs_Read.txt\"):\n",
    "        if l.startswith(\"userID\"): # it's just the header\n",
    "            predictions.write(l)\n",
    "            continue\n",
    "        user, book = l.strip().split('-') # it is a datapoint\n",
    "        prediction = predict_datapoint(user, book)\n",
    "        if prediction:\n",
    "            predictions.write(user + '-' + book + \",1\\n\")\n",
    "        else:\n",
    "            predictions.write(user + '-' + book + \",0\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ratings Prediction\n",
    "\n",
    "train_size = 170000\n",
    "data       = [line for line in readCSV(\"train_Interactions.csv.gz\")]\n",
    "random.shuffle(data)\n",
    "train      = data[:train_size]\n",
    "val        = data[train_size:]\n",
    "\n",
    "allRatings = []\n",
    "userBookRatings = defaultdict(lambda: defaultdict(float))\n",
    "userRatings = defaultdict(list)\n",
    "userBooks   = defaultdict(set)\n",
    "bookUsers   = defaultdict(set)\n",
    "\n",
    "for user, book, rating in train:\n",
    "    rating = int(rating)\n",
    "    allRatings.append(rating)\n",
    "    userRatings[user].append(rating)\n",
    "    userBookRatings[user][book] = rating\n",
    "    userBooks[user].add(book)\n",
    "    bookUsers[book].add(user)\n",
    "\n",
    "globalAverage = sum(allRatings) / len(allRatings)\n",
    "userAverage = {}\n",
    "for user in userRatings:\n",
    "    userAverage[user] = sum(userRatings[user]) / len(userRatings[user])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinate Descent\n",
    "\n",
    "def coordinate_descent(lambda_opt = 1, iterations = 100):\n",
    "\n",
    "    alpha_sum, bu_sum, bb_sum = 0, 0, 0\n",
    "\n",
    "    train_len = len(train)\n",
    "    bu = defaultdict(lambda: 1)\n",
    "    bb = defaultdict(lambda: 1)\n",
    "\n",
    "    for descent in range(iterations):\n",
    "        alpha_sum = 0\n",
    "        for user, book, _ in train:\n",
    "            alpha_sum += userBookRatings[user][book] - (bu[user] + bb[book])\n",
    "        alpha = alpha_sum / train_len\n",
    "\n",
    "        for user in userRatings:\n",
    "            bu_sum = 0\n",
    "            for book in userBooks[user]:\n",
    "                bu_sum += userBookRatings[user][book] - (alpha + bb[book])\n",
    "            bu[user] = bu_sum / (lambda_opt + len(userBooks[user]))\n",
    "\n",
    "        for book in bookUsers:\n",
    "            bb_sum = 0\n",
    "            for user in bookUsers[book]:\n",
    "                bb_sum += userBookRatings[user][book] - (alpha + bu[user])\n",
    "            bb[book] = bb_sum / (lambda_opt + len(bookUsers[book]))\n",
    "            \n",
    "    return alpha, bu, bb\n",
    "\n",
    "alpha, bu, bb = coordinate_descent(lambda_opt = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_labels = []\n",
    "diff = 0\n",
    "for user, book, rating in val:\n",
    "    user_rating = alpha + bu[user] + bb[book]\n",
    "    diff += (user_rating - int(rating)) ** 2\n",
    "\n",
    "MSE = diff / len(val)\n",
    "print(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_values = np.logspace(-1, 1.5, num = 40)\n",
    "print(lambda_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSEs = []\n",
    "loop_count = 0\n",
    "for lambda_opt in lambda_values:\n",
    "    loop_count += 1; print(loop_count, end = ', ')\n",
    "    alpha, bu, bb = coordinate_descent(lambda_opt, iterations = 20)\n",
    "    rating_labels = []\n",
    "    diff = 0\n",
    "    for user, book, rating in val:\n",
    "        user_rating = alpha + bu[user] + bb[book]\n",
    "        diff += (user_rating - int(rating)) ** 2\n",
    "    MSE = diff / len(val)\n",
    "    MSEs.append(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lambda_values, MSEs, label='Validation')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('lambda value'), plt.xscale('log')\n",
    "plt.title('MSE vs lambda values')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indx = MSEs.index(min(MSEs))\n",
    "print('\\nLambda for lowest MSE is:', lambda_values[indx])\n",
    "print('\\nBest MSE is:', MSEs[indx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above graph shows..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently I got the best performance with lambda = 2.8\n",
    "# (for test set on kaggle)\n",
    "alpha, bu, bb = coordinate_descent(2.8, iterations = 100)\n",
    "# alpha, bu, bb = coordinate_descent(lambda_values[indx], iterations = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"predictions_Rating.txt\", 'w') as predictions:\n",
    "    for l in open(\"pairs_Rating.txt\"):\n",
    "        if l.startswith(\"userID\"):\n",
    "            #header\n",
    "            predictions.write(l)\n",
    "            continue\n",
    "        user, book = l.strip().split('-')\n",
    "        user_rating = alpha + bu[user] + bb[book]\n",
    "        predictions.write(user + '-' + book + ',' + str(user_rating) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
