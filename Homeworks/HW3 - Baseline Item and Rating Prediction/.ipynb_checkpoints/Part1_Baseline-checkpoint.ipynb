{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        yield eval(l)\n",
    "\n",
    "def readCSV(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        yield l.strip().split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['u79354815', 'b14275065', '4']\n"
     ]
    }
   ],
   "source": [
    "example = readCSV(\"train_Interactions.csv.gz\")\n",
    "print(next(example))\n",
    "del example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n",
      "190000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "### Would-read baseline: just rank which books are \n",
    "### popular and which are not, and return '1' if a\n",
    "### book is among the top-ranked\n",
    "train_size = 190000\n",
    "val_size   = 10000\n",
    "\n",
    "data = [line for line in readCSV(\"train_Interactions.csv.gz\")]\n",
    "train = data[:train_size]\n",
    "val   = data[train_size:]\n",
    "print(len(data))\n",
    "print(len(train))\n",
    "print(len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "[['u35176258', 'b30592470', '3'], ['u30851063', 'b81941226', '3'], ['u31368414', 'b40097012', '5']]\n"
     ]
    }
   ],
   "source": [
    "booksReadBy = defaultdict(set)\n",
    "train_booksReadBy = defaultdict(set)\n",
    "val_booksReadBy = defaultdict(set)\n",
    "usersReadBook = defaultdict(set)\n",
    "val_usersReadBook = defaultdict(set)\n",
    "train_usersReadBook = defaultdict(set)\n",
    "all_books = set()\n",
    "val_all_books = set()\n",
    "train_all_books = set()\n",
    "    \n",
    "for user, book, _ in data:\n",
    "    all_books.add(book)\n",
    "    usersReadBook[book].add(user)\n",
    "    booksReadBy[user].add(book)\n",
    "\n",
    "for user, book, _ in train:\n",
    "    train_all_books.add(book)\n",
    "    train_usersReadBook[book].add(user)\n",
    "    train_booksReadBy[user].add(book)\n",
    "\n",
    "for user, book, _ in val:\n",
    "    val_all_books.add(book)\n",
    "    val_usersReadBook[book].add(user)\n",
    "    val_booksReadBy[user].add(book)\n",
    "\n",
    "val_unread = []\n",
    "all_books_count = len(all_books)\n",
    "for user, book, _ in val: \n",
    "    unread_book = random.sample(all_books, 1)\n",
    "    while(unread_book in list(booksReadBy[user])):\n",
    "        unread_book = random.sample(all_books, 1)\n",
    "    val_unread.append([user, str(unread_book[0]), '-1'])\n",
    "\n",
    "val = val + val_unread\n",
    "print(len(val))\n",
    "print(val[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookCount = defaultdict(int)\n",
    "total_books_read = 0\n",
    "\n",
    "for user, book, _ in train:\n",
    "    bookCount[book]  += 1\n",
    "    total_books_read += 1\n",
    "\n",
    "mostPopular = [(bookCount[book], book) for book in bookCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def popular_books_set(mostPopular, threshold_ratio):\n",
    "    return1 = set()\n",
    "    cur_book_count = 0\n",
    "    for book_count, book in mostPopular:\n",
    "        cur_book_count += book_count\n",
    "        return1.add(book)\n",
    "        if cur_book_count > total_books_read *\\\n",
    "        threshold_ratio: \n",
    "            break\n",
    "    return return1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(set1, set2):\n",
    "    \"\"\"\n",
    "    Returns the Jaccard similarity between two sets,\n",
    "    set1 & set2\n",
    "    \"\"\"\n",
    "    set_intersection = len(set1.intersection(set2))\n",
    "    set_union = len(set1.union(set2))\n",
    "    if set_union == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return set_intersection / set_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_prediction(jac_sims):\n",
    "    \"\"\"\n",
    "    Returns the Jaccard similarity between two sets,\n",
    "    set1 & set2\n",
    "    \"\"\"\n",
    "    prediction = False\n",
    "    if jac_sims != []:\n",
    "        prediction = max(jac_sims) >= jaccard_threshold\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "sizes = 10\n",
    "pops = np.linspace(0.2, 0.7, sizes)\n",
    "jaccards = np.linspace(0.01, 0.1, sizes)\n",
    "print(len(pops))\n",
    "print(len(jaccards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_jac(user, book_predict):\n",
    "    books_user_read = train_booksReadBy[user]\n",
    "    jac_sims = []\n",
    "    for users_book in books_user_read:   \n",
    "        users_read_book_predict = train_usersReadBook[book_predict]\n",
    "        users_read_users_book = train_usersReadBook[users_book]\n",
    "        jac_sim = jaccard(users_read_book_predict, users_read_users_book)\n",
    "        jac_sims.append(jac_sim)\n",
    "    return jac_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_jac_train(user, book_predict):\n",
    "    books_user_read = train_booksReadBy[user]\n",
    "    jac_sims = []\n",
    "    for users_book in books_user_read:  \n",
    "        if users_book == book_predict: continue\n",
    "        users_read_book_predict = train_usersReadBook[book_predict]\n",
    "        users_read_users_book = train_usersReadBook[users_book]\n",
    "        jac_sim = jaccard(users_read_book_predict, users_read_users_book)\n",
    "        jac_sims.append(jac_sim)\n",
    "    return jac_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_LR = train\n",
    "train_unread = []\n",
    "\n",
    "for user, book, _ in train: \n",
    "    unread_book = random.sample(all_books, 1)\n",
    "    while(unread_book in list(booksReadBy[user])):\n",
    "        unread_book = random.sample(all_books, 1)\n",
    "    train_unread.append([user, str(unread_book[0]), '-1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(datum, func):\n",
    "    user, book, _ = datum\n",
    "    jac_sims = func(user, book)\n",
    "    if jac_sims == []: jac_val = 0\n",
    "    else: jac_val = max(jac_sims)\n",
    "    pop_val = book in return1\n",
    "    feat = [1]\n",
    "    feat.append(pop_val)\n",
    "    feat.append(jac_val)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return1 = popular_books_set(mostPopular, 0.64)\n",
    "train_LR = train + train_unread\n",
    "LR_feat_train   = np.array([feature(d, calc_jac_train) for d in train_LR])\n",
    "LR_labels_train = [int(rating) >= 0 for _, _, rating in train_LR]\n",
    "LR_feat_val  = np.array([feature(d, calc_jac) for d in val])\n",
    "LR_labels_val = [int(rating) >= 0 for _, _, rating in val]\n",
    "\n",
    "C_values = np.logspace(-2, 0, num = 40)\n",
    "accs = []\n",
    "loop_count = 0\n",
    "for C_value in C_values:\n",
    "    loop_count += 1\n",
    "    if loop_count % 10 == 0: print(loop_count, end = ', ')\n",
    "    clf = LogisticRegression(C = C_value).fit(LR_feat_train, LR_labels_train)\n",
    "    acc = clf.score(LR_feat_val, LR_labels_val)\n",
    "    accs.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(C_values, accs, label='Validation')\n",
    "plt.ylabel('Validation accuracy')\n",
    "plt.xlabel('lambda value'), plt.xscale('log')\n",
    "plt.title('Validation accuracy vs C values')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "indx = accs.index(max(accs))\n",
    "print('\\nC value for highest accuracy is:', C_values[indx])\n",
    "print('Best validation accuracy is:', accs[indx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_datapoint_old(user, book_predict):\n",
    "    books_user_read = booksReadBy[user]\n",
    "    jac_sims = calc_jac(user, book_predict)\n",
    "    prediction_jac = max(jac_sims) >= jaccard_threshold\n",
    "    prediction_pop = book_predict in return1\n",
    "    prediction = prediction_jac or prediction_pop          \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C = C_values[indx]).fit(LR_feat_train, LR_labels_train)\n",
    "def predict_datapoint_new(user, book_predict):\n",
    "    feat = np.array(feature((user, book_predict,_), calc_jac_train))\n",
    "    prediction = clf.predict(feat)       \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = []\n",
    "for l in open(\"pairs_Read.txt\"):\n",
    "    if l.startswith(\"userID\"): # it's just the header\n",
    "        continue\n",
    "    user, book = l.strip().split('-') # it is a datapoint\n",
    "    test_set.append((user, book, _))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test   = np.array([feature(d, calc_jac) for d in test_set])\n",
    "y_test   = [int(rating) >= 0 for _, _, rating in test_set]\n",
    "confidence_scores = clf.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_count = sum(clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slack = 200\n",
    "conf_with_labels = zip(confidence_scores, [(d[0],d[1]) for d in test_set])\n",
    "conf_with_labels = list(conf_with_labels)\n",
    "conf_with_labels.sort(reverse = True)\n",
    "positives = conf_with_labels[:pos_count + slack]\n",
    "negatives = conf_with_labels[pos_count + slack:]\n",
    "positives = [d[1] for d in positives]\n",
    "negatives = [d[1] for d in negatives]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "with open(\"predictions_Read.txt\", 'w') as predictions:\n",
    "    for l in open(\"pairs_Read.txt\"):\n",
    "        if l.startswith(\"userID\"): # it's just the header\n",
    "            predictions.write(l)\n",
    "            continue\n",
    "        user, book = l.strip().split('-') # it is a datapoint\n",
    "        if (user, book) in positives:\n",
    "            count += 1\n",
    "            predictions.write(user + '-' + book + \",1\\n\")\n",
    "        else:\n",
    "            predictions.write(user + '-' + book + \",0\\n\")\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = []\n",
    "with open(\"predictions_Read.txt\", 'w') as predictions:\n",
    "    for l in open(\"pairs_Read.txt\"):\n",
    "        if l.startswith(\"userID\"): # it's just the header\n",
    "            predictions.write(l)\n",
    "            continue\n",
    "        user, book = l.strip().split('-') # it is a datapoint\n",
    "        test_set.append(user, book)\n",
    "        prediction = predict_datapoint_new(user, book)\n",
    "        if prediction:\n",
    "            predictions.write(user + '-' + book + \",1\\n\")\n",
    "        else:\n",
    "            predictions.write(user + '-' + book + \",0\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
