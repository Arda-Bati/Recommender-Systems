{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        yield eval(l)\n",
    "\n",
    "def readCSV(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        yield l.strip().split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_read = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"predictions_Rating.txt\", 'w') as predictions:\n",
    "    for l in open(\"pairs_Rating.txt\"):\n",
    "        if l.startswith(\"userID\"):\n",
    "            #header\n",
    "            predictions.write(l)\n",
    "            continue\n",
    "        user, book = l.strip().split('-')\n",
    "        rating_read.append((user, book, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210000\n",
      "200000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "### Would-read baseline: just rank which books are \n",
    "### popular and which are not, and return '1' if a\n",
    "### book is among the top-ranked\n",
    "train_size = 200000\n",
    "\n",
    "data = [line for line in readCSV(\"train_Interactions.csv.gz\")]\n",
    "random.shuffle(data)\n",
    "data = data + rating_read\n",
    "train = data[:train_size]\n",
    "val   = data[train_size:]\n",
    "print(len(data))\n",
    "print(len(train))\n",
    "print(len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "allRatings = []\n",
    "userBookRatings = defaultdict(lambda: defaultdict(float))\n",
    "train_booksReadBy = defaultdict(set)\n",
    "train_usersReadBook = defaultdict(set)\n",
    "train_all_books = set()\n",
    "all_booksReadBy = defaultdict(set)\n",
    "all_usersReadBook = defaultdict(set)\n",
    "all_books    = set()\n",
    "all_users    = set()\n",
    "    \n",
    "for user, book, rating in data:\n",
    "    rating = int(rating)\n",
    "    allRatings.append(rating)\n",
    "    all_booksReadBy[user].add(book)\n",
    "    all_usersReadBook[book].add(user)\n",
    "    all_books.add(book)\n",
    "    all_users.add(user)\n",
    "    \n",
    "for user, book, rating in train:\n",
    "    userBookRatings[user][book] = int(rating)\n",
    "    train_all_books.add(book)\n",
    "    train_usersReadBook[book].add(user)\n",
    "    train_booksReadBy[user].add(book)\n",
    "    \n",
    "bookCount = defaultdict(int)\n",
    "userCount = defaultdict(int)\n",
    "total_books_read = 0\n",
    "\n",
    "for user, book, _ in train:\n",
    "    bookCount[book]  += 1\n",
    "    total_books_read += 1\n",
    "\n",
    "mostPopular      = [(bookCount[book], book) for book in bookCount]\n",
    "mostPopular.sort(reverse = True)\n",
    "def popular_books_set(mostPopular, threshold_ratio):\n",
    "    return1 = set()\n",
    "    cur_book_count = 0\n",
    "    for book_count, book in mostPopular:\n",
    "        cur_book_count += book_count\n",
    "        return1.add(book)\n",
    "        if cur_book_count > total_books_read * threshold_ratio: \n",
    "            break\n",
    "    return return1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "[('u64492429', 'b61759371', 4), ['u88970409', 'b01248465', '-1'], ('u68375581', 'b58950783', 4)]\n"
     ]
    }
   ],
   "source": [
    "val_unread = []\n",
    "for user, book, _ in val: \n",
    "    unread_book = random.sample(all_books, 1)\n",
    "    while(unread_book in list(all_booksReadBy[user])):\n",
    "        unread_book = random.sample(all_books, 1)\n",
    "    val_unread.append([user, str(unread_book[0]), '-1'])\n",
    "\n",
    "val = val + val_unread\n",
    "random.shuffle(val)\n",
    "print(len(val))\n",
    "print(val[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_LR = train\n",
    "train_unread = []\n",
    "\n",
    "for user, book, _ in train: \n",
    "    unread_book = random.sample(all_books, 1)\n",
    "    while(unread_book in list(all_booksReadBy[user])):\n",
    "        unread_book = random.sample(all_books, 1)\n",
    "    train_unread.append([user, str(unread_book[0]), '-1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sims_max_value(sims):\n",
    "    prediction = False\n",
    "    top5_ave   = 0\n",
    "    if sims != []:\n",
    "        prediction = max(sims)\n",
    "        top5_ave = sum(sims[:5]) / min(5, len(sims))\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JACCARD FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(set1, set2):\n",
    "    \"\"\"\n",
    "    Returns the Jaccard similarity between two sets,\n",
    "    set1 & set2\n",
    "    \"\"\" \n",
    "    set_intersection = len(set1.intersection(set2))\n",
    "    set_union = len(set1.union(set2))\n",
    "    if set_intersection == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return set_intersection / set_union\n",
    "    \n",
    "def calc_jac_books(user, book_predict, mode = 'train'):\n",
    "    books_user_read = train_booksReadBy[user]\n",
    "    jac_sims = []\n",
    "    \n",
    "    for users_book in books_user_read:  \n",
    "        if users_book == book_predict: \n",
    "            if mode == 'train': continue\n",
    "            # else: return 1\n",
    "            \n",
    "        users_read_book_predict = train_usersReadBook[book_predict]\n",
    "        users_read_users_book   = train_usersReadBook[users_book]\n",
    "        jac_sim = jaccard(users_read_book_predict, users_read_users_book)\n",
    "        jac_sims.append(jac_sim)\n",
    "    return jac_sims\n",
    "\n",
    "def calc_jac_users(user_predict, book, mode = 'train'):\n",
    "    user_read_book = train_usersReadBook[book]\n",
    "    jac_sims = []\n",
    "    for user in user_read_book:   \n",
    "        if user == user_predict: \n",
    "            if mode == 'train': continue\n",
    "        books_user_read          = train_booksReadBy[user_predict]\n",
    "        books_user_predict_read  = train_booksReadBy[user]  \n",
    "        jac_sim = jaccard(books_user_read, books_user_predict_read)\n",
    "        jac_sims.append(jac_sim)\n",
    "    return jac_sims\n",
    "\n",
    "def calc_jac_users_alt(user_predict, book, mode = 'train'):\n",
    "    user_read_book = train_usersReadBook[book]\n",
    "    jac_sims = []\n",
    "    for user in user_read_book:   \n",
    "        if user == user_predict: \n",
    "            if mode == 'train': continue\n",
    "        books_user_read          = train_booksReadBy[user_predict]\n",
    "        books_user_predict_read  = train_booksReadBy[user]\n",
    "        jac_sim = jaccard(books_user_read, books_user_predict_read)\n",
    "        jac_sims.append((jac_sim, user))\n",
    "    if len(jac_sims) == 0: return 0\n",
    "    jac_sims.sort(reverse = True)\n",
    "    for user in jac_sims[:10]:\n",
    "        if book in train_booksReadBy[user]: return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COSINE FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "allRatings = []\n",
    "userRatings = defaultdict(list)\n",
    "bookRatings = defaultdict(list)\n",
    "\n",
    "for user, book, rating in readCSV(\"train_Interactions.csv.gz\"):\n",
    "    rating = int(rating)\n",
    "    allRatings.append(rating)\n",
    "    userRatings[user].append(rating)\n",
    "    bookRatings[book].append(rating)\n",
    "\n",
    "bookAverage = {}\n",
    "for book in bookRatings:\n",
    "    bookAverage[book] = sum(bookRatings[book]) / len(bookRatings[book])\n",
    "\n",
    "userAverage = {}\n",
    "for user in userRatings:\n",
    "    userAverage[user] = sum(userRatings[user]) / len(userRatings[user])\n",
    "    \n",
    "def cos_sim_books(book1, book2):\n",
    "    if book1 == book2: return 1\n",
    "    users_read_both = list(train_usersReadBook[book1]) + list(train_usersReadBook[book2])\n",
    "    users_read_both = set(users_read_both)\n",
    "    book1_ratings = 0\n",
    "    book2_ratings = 0\n",
    "    zero_users = set()\n",
    "    for user in users_read_both:\n",
    "        if userBookRatings[user][book1] == 0: zero_users.add(user)\n",
    "        if userBookRatings[user][book2] == 0: zero_users.add(user)\n",
    "    for zero_user in zero_users:\n",
    "        users_read_both.remove(zero_user)\n",
    "\n",
    "    if len(users_read_both) == 0: return 0\n",
    "    \n",
    "    numerator_sum = 0; denom_sum1 = 0; denom_sum2 = 0\n",
    "    for user in users_read_both:\n",
    "        arg1 = (userBookRatings[user][book1] > userAverage[user]) * 2 - 1\n",
    "        arg2 = (userBookRatings[user][book2] > userAverage[user]) * 2 - 1\n",
    "        numerator_sum += arg1 * arg2\n",
    "        denom_sum1 += arg1 ** 2\n",
    "        denom_sum2 += arg2 ** 2 \n",
    "    denom = denom_sum1 * denom_sum2\n",
    "    if denom == 0: return 0\n",
    "    cosine_sim = numerator_sum / (denom ** 0.5)\n",
    "    \n",
    "    return cosine_sim\n",
    "\n",
    "def cos_sim_users(user1, user2):\n",
    "    if user1 == user2: return 1\n",
    "    books_readby_both = list(train_booksReadBy[user1]) + list(train_booksReadBy[user2])\n",
    "    books_readby_both = set(books_readby_both)\n",
    "    user1_ratings = 0\n",
    "    user2_ratings = 0\n",
    "    zero_books = set()\n",
    "    for book in books_readby_both:\n",
    "        if userBookRatings[user1][book] == 0: zero_books.add(book)\n",
    "        if userBookRatings[user2][book] == 0: zero_books.add(book)\n",
    "    for zero_book in zero_books:\n",
    "        books_readby_both.remove(zero_book)\n",
    "\n",
    "    if len(books_readby_both) == 0: return 0\n",
    "    \n",
    "    numerator_sum = 0; denom_sum1 = 0; denom_sum2 = 0\n",
    "    for book in books_readby_both:\n",
    "        arg1 = (userBookRatings[user1][book] > bookAverage[book]) * 2 - 1\n",
    "        arg2 = (userBookRatings[user2][book] > bookAverage[book]) * 2 - 1\n",
    "        # LEFT HERE\n",
    "        numerator_sum += arg1 * arg2\n",
    "        denom_sum1 += arg1 ** 2\n",
    "        denom_sum2 += arg2 ** 2 \n",
    "    denom = denom_sum1 * denom_sum2\n",
    "    if denom == 0: return 0\n",
    "    cosine_sim = numerator_sum / (denom ** 0.5)\n",
    "    \n",
    "    return cosine_sim\n",
    "\n",
    "def calc_cosine_books(user, book_predict, mode = 'train'):\n",
    "    books_user_read = train_booksReadBy[user]\n",
    "    cosine_sims = []\n",
    "    for users_book in books_user_read:  \n",
    "        if users_book == book_predict:\n",
    "            if mode == 'train': continue\n",
    "            # else: return 1\n",
    "        cosine_sim = cos_sim_books(users_book, book_predict)\n",
    "        cosine_sims.append(cosine_sim)\n",
    "    return cosine_sims\n",
    "\n",
    "def calc_cosine_users(user_predict, book, mode = 'train'):\n",
    "    user_read_book = train_usersReadBook[book]\n",
    "    cosine_sims = []\n",
    "    for user in user_read_book:  \n",
    "        if user == user_predict:\n",
    "            if mode == 'train': continue\n",
    "            # else: return 1\n",
    "        cosine_sim = cos_sim_users(user, user_predict)\n",
    "        cosine_sims.append(cosine_sim)\n",
    "    return cosine_sims\n",
    "\n",
    "def calc_cosine_users_alt(user_predict, book, mode = 'train'):\n",
    "    user_read_book = train_usersReadBook[book]\n",
    "    cosine_sims = []\n",
    "    for user in user_read_book:  \n",
    "        if user == user_predict:\n",
    "            if mode == 'train': continue\n",
    "            # else: return 1\n",
    "        cosine_sim = cos_sim_users(user, user_predict)\n",
    "        cosine_sims.append(cosine_sim)\n",
    "    if len(cosine_sims) == 0: return 0\n",
    "    cosine_sims.sort(reverse = True)\n",
    "    for user in cosine_sims[:10]:\n",
    "        if book in train_booksReadBy[user]: return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PEARSON FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_sim(book1, book2):\n",
    "    if book1 == book2: return 1\n",
    "    users_read_both = list(train_usersReadBook[book1]) + list(train_usersReadBook[book2])\n",
    "    users_read_both = set(users_read_both)\n",
    "    book1_ratings = 0\n",
    "    book2_ratings = 0\n",
    "    zero_users = set()\n",
    "    for user in users_read_both:\n",
    "        if userBookRatings[user][book1] == 0: zero_users.add(user)\n",
    "        if userBookRatings[user][book2] == 0: zero_users.add(user)\n",
    "    for zero_user in zero_users:\n",
    "        users_read_both.remove(zero_user)\n",
    "\n",
    "    if len(users_read_both) == 0: return 0\n",
    "\n",
    "    for user in users_read_both:\n",
    "        book1_ratings += userBookRatings[user][book1]\n",
    "        book2_ratings += userBookRatings[user][book2]\n",
    "    \n",
    "    book1_ratings = book1_ratings / len(users_read_both)\n",
    "    book2_ratings = book2_ratings / len(users_read_both)\n",
    "    numerator_sum = 0; denom_sum1 = 0; denom_sum2 = 0\n",
    "    for user in users_read_both:\n",
    "        arg1 = (userBookRatings[user][book1] - book1_ratings)\n",
    "        arg2 = (userBookRatings[user][book2] - book2_ratings)\n",
    "        # print(arg1, arg2)\n",
    "        numerator_sum += arg1 * arg2\n",
    "        denom_sum1 += arg1 ** 2\n",
    "        denom_sum2 += arg2 ** 2\n",
    "    denom = denom_sum1 * denom_sum2\n",
    "    # print(numerator_sum)\n",
    "    # print(denom_sum1, denom_sum2)\n",
    "    if denom == 0: return 0\n",
    "    pearson_sim = numerator_sum / (denom ** 0.5)\n",
    "    \n",
    "    if pearson_sim == 1: # Probably very low number of books in common\n",
    "        return min(1, 0.2 * len(users_read_both))\n",
    "    return pearson_sim\n",
    "\n",
    "def calc_pearson(user, book_predict, mode):\n",
    "    books_user_read = train_booksReadBy[user]\n",
    "    pears_sims = []\n",
    "    for users_book in books_user_read:  \n",
    "        if users_book == book_predict: \n",
    "            if mode == 'train': continue  \n",
    "            else: return 1\n",
    "        pears_sim = pearson_sim(users_book, book_predict)\n",
    "        pears_sims.append(pears_sim)\n",
    "    return sims_max_value(pears_sims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(datum, mode = 'train'):\n",
    "    user, book, _ = datum\n",
    "    feat = [1]\n",
    "    \n",
    "    pop_val = (book in return1) * 1; \n",
    "    feat.append(pop_val)\n",
    "    \n",
    "    jac_sims_book = calc_jac_books(user, book, mode); \n",
    "    if len(jac_sims_book) != 0:\n",
    "        feat.append(max(jac_sims_book)); \n",
    "        # feat.append(len(jac_sims_book));\\\n",
    "        feat.append(sum(jac_sims_book) / len(jac_sims_book))\n",
    "    else:\n",
    "        feat.append(0); \n",
    "        # feat.append(0);\n",
    "        feat.append(0)\n",
    "    \n",
    "    jac_sims_user = calc_jac_users(user, book, mode); \n",
    "    if len(jac_sims_user) != 0:\n",
    "        feat.append(max(jac_sims_user)); \n",
    "        feat.append(len(jac_sims_user));\\\n",
    "        feat.append(sum(jac_sims_user) / len(jac_sims_user))\n",
    "    else:\n",
    "        feat.append(0); \n",
    "        feat.append(0); \n",
    "        feat.append(0)\n",
    "        \n",
    "    cosine_sim_book = calc_cosine_books(user, book, mode);\n",
    "    if len(cosine_sim_book) != 0:\n",
    "        feat.append(max(cosine_sim_book))\n",
    "        feat.append(sum(cosine_sim_book) / len(cosine_sim_book))\n",
    "    else:\n",
    "        feat.append(0)\n",
    "        feat.append(0)\n",
    "        \n",
    "    cosine_sim_user = calc_cosine_users(user, book, mode);\n",
    "    if len(cosine_sim_user) != 0:\n",
    "        feat.append(max(cosine_sim_user))\n",
    "        feat.append(sum(cosine_sim_user) / len(cosine_sim_user))\n",
    "    else:\n",
    "        feat.append(0)\n",
    "        feat.append(0)\n",
    "        \n",
    "#     pearson_sim_book = calc_pearson(user, book, mode); \n",
    "#     feat.append(pearson_sim_book)\n",
    "    \n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "return1 = popular_books_set(mostPopular, 0.64)\n",
    "train_LR = train + train_unread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "10000, 20000, "
     ]
    }
   ],
   "source": [
    "random.shuffle(train_LR)\n",
    "train_LR = train_LR[:20000]\n",
    "loop_count = 0\n",
    "LR_feat_train = []\n",
    "print('here')\n",
    "for d in train_LR:\n",
    "    loop_count += 1\n",
    "    if loop_count % 10000 == 0: print(loop_count, end = ', ');\n",
    "    LR_feat_train.append(feature(d, mode = 'train'))\n",
    "LR_labels_train = [int(rating) >= 0 for _, _, rating in train_LR]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "10000, 20000, "
     ]
    }
   ],
   "source": [
    "loop_count = 0\n",
    "LR_feat_val = []\n",
    "print('here')\n",
    "for d in val:\n",
    "    loop_count += 1\n",
    "    if loop_count % 10000 == 0: print(loop_count, end = ', ');\n",
    "    LR_feat_val.append(feature(d, mode = 'train'))\n",
    "LR_labels_val   = [int(rating) >= 0 for _, _, rating in val]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balanced Error Rate function\n",
    "def balanced_error_rate(pred, labels):\n",
    "    TP_ = np.logical_and(pred, labels)\n",
    "    FP_ = np.logical_and(pred, np.logical_not(labels))\n",
    "    TN_ = np.logical_and(np.logical_not(pred), np.logical_not(labels))\n",
    "    FN_ = np.logical_and(np.logical_not(pred), labels)\n",
    "\n",
    "    TP = sum(TP_)\n",
    "    FP = sum(FP_)\n",
    "    TN = sum(TN_)\n",
    "    FN = sum(FN_)\n",
    "    \n",
    "    acc = (TP + TN) / (TP + FP + TN + FN)\n",
    "    BER = 1 - 0.5 * (TP / (TP + FN) + TN / (TN + FP))\n",
    "    return acc, BER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5, 10, 15, 20, "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "C value for highest accuracy is: 3359818286.2837744\n",
      "Best validation accuracy is: 0.84155\n"
     ]
    }
   ],
   "source": [
    "C_values = np.logspace(1, 10, num = 20)\n",
    "accs = []\n",
    "BERs = []\n",
    "loop_count = 0\n",
    "for C_value in C_values:\n",
    "    loop_count += 1\n",
    "    if loop_count % 5 == 0: print(loop_count, end = ', ')\n",
    "    clf = LogisticRegression(C = C_value).fit(LR_feat_val, LR_labels_val)\n",
    "    predicitons = clf.predict(LR_feat_train)\n",
    "    acc, BER = balanced_error_rate(predicitons, LR_labels_train)\n",
    "    # acc = clf.score(LR_feat_val, LR_labels_val)\n",
    "    accs.append(acc)\n",
    "    BERs.append(BER)\n",
    "\n",
    "plt.plot(C_values, accs, label='Validation accuracy')\n",
    "plt.plot(C_values, BERs, label='Validation BER')\n",
    "plt.ylabel('Validation accuracy')\n",
    "plt.xlabel('lambda value'), plt.xscale('log')\n",
    "plt.title('Validation accuracy vs C values')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "indx = accs.index(max(accs))\n",
    "print('\\nC value for highest accuracy is:', C_values[indx])\n",
    "print('Best validation accuracy is:', accs[indx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C = 200 0.68983 accuracy validation size 40000\n",
    "# C = 300 \n",
    "clf1 = LogisticRegression(C = C_values[indx]).fit(LR_feat_train, LR_labels_train)\n",
    "# clf1 = LogisticRegression(C = 0.003359818286283781).fit(LR_feat_train, LR_labels_train)\n",
    "clf2 = LogisticRegression(C = 300).fit(LR_feat_val, LR_labels_val)\n",
    "def predict_datapoint_new(user, book_predict):\n",
    "    feat = np.array(feature((user, book_predict,_), mode = 'train'))\n",
    "    feat = feat.reshape(1, -1)\n",
    "    prediction = clf.predict(feat)       \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WRITING PREDICTIONS TO FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_set = []\n",
    "# for l in open(\"pairs_Read.txt\"):\n",
    "#     if l.startswith(\"userID\"): # it's just the header\n",
    "#         continue\n",
    "#     user, book = l.strip().split('-') # it is a datapoint\n",
    "#     test_set.append((user, book, _))\n",
    "\n",
    "# X_test   = np.array([feature(d, 'test') for d in test_set])\n",
    "# y_test   = [int(rating) >= 0 for _, _, rating in test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = LogisticRegression(C = 300).fit(LR_feat_val, LR_labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(LR_feat_val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "pos_count = 0\n",
    "def predict_datapoint_new(clf, user, book):\n",
    "    feat = np.array(feature((user, book, _), 'test'))\n",
    "    feat = feat.reshape(1, -1)\n",
    "    prediction = clf.decision_function(feat)       \n",
    "    return prediction\n",
    "\n",
    "count = 0;\n",
    "userPredictions = defaultdict(list)\n",
    "userPredictions2D = defaultdict(lambda: defaultdict(set))\n",
    "\n",
    "# confidence_scores = clf2.decision_function(X_test)\n",
    "\n",
    "with open(\"predictions_Read.txt\", 'w') as predictions:\n",
    "    for l in open(\"pairs_Read.txt\"):\n",
    "        if l.startswith(\"userID\"): # it's just the header\n",
    "            predictions.write(l)\n",
    "            continue\n",
    "        user, book = l.strip().split('-') # it is a datapoint\n",
    "        userPredictions[user].append((predict_datapoint_new(clf2, user, book), book))\n",
    "\n",
    "for user in userPredictions:\n",
    "    userPredictions[user].sort(reverse = True)\n",
    "    books = [d[1] for d in userPredictions[user]]\n",
    "    for i in range(len(books)):\n",
    "        userPredictions2D[user][books[i]] = 0\n",
    "    for i in range(int(len(books)/2)):\n",
    "        userPredictions2D[user][books[i]] = 1\n",
    "\n",
    "count = 0\n",
    "with open(\"predictions_Read.txt\", 'w') as predictions:\n",
    "    for l in open(\"pairs_Read.txt\"):\n",
    "        if l.startswith(\"userID\"): # it's just the header\n",
    "            predictions.write(l)\n",
    "            continue\n",
    "        user, book = l.strip().split('-') # it is a datapoint\n",
    "        prediction = userPredictions2D[user][book]\n",
    "        if prediction:\n",
    "            count += 1\n",
    "            predictions.write(user + '-' + book + \",1\\n\")\n",
    "        else:\n",
    "            predictions.write(user + '-' + book + \",0\\n\")\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1 = clf1.predict(X_test)\n",
    "predictions2 = clf2.predict(X_test)\n",
    "preds = (predictions1 + predictions2) * 1 > sum((predictions1 + predictions2) * 1) / len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aver = sum((predictions1 + predictions2) * 1) / len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_count = sum(clf2.predict(X_test))\n",
    "print(pos_count)\n",
    "\n",
    "offset = 0\n",
    "conf_with_labels = zip(confidence_scores, [(d[0],d[1]) for d in test_set])\n",
    "conf_with_labels = list(conf_with_labels)\n",
    "conf_with_labels.sort(reverse = True)\n",
    "positives = conf_with_labels[:pos_count + offset]\n",
    "negatives = conf_with_labels[pos_count + offset:]\n",
    "positives = [d[1] for d in positives]\n",
    "negatives = [d[1] for d in negatives]\n",
    "print(len(positives))\n",
    "print(len(negatives))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_count = 0\n",
    "def predict_datapoint_new(clf, user, book):\n",
    "    feat = np.array(feature((user, book,_), 'test'))\n",
    "    feat = feat.reshape(1, -1)\n",
    "    prediction = clf.predict(feat)       \n",
    "    return prediction\n",
    "\n",
    "with open(\"predictions_Read.txt\", 'w') as predictions:\n",
    "    for l in open(\"pairs_Read.txt\"):\n",
    "        if l.startswith(\"userID\"): # it's just the header\n",
    "            predictions.write(l)\n",
    "            continue\n",
    "        user, book = l.strip().split('-') # it is a datapoint\n",
    "        prediction1 = predict_datapoint_new(clf1, user, book)\n",
    "        prediction2 = predict_datapoint_new(clf2, user, book)\n",
    "        prediction = (prediction1 + prediction2) * 1 > aver\n",
    "        if prediction:\n",
    "            pos_count += 1\n",
    "            predictions.write(user + '-' + book + \",1\\n\")\n",
    "        else:\n",
    "            predictions.write(user + '-' + book + \",0\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pos_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 3\n",
    "def fun():\n",
    "    global x\n",
    "    x = 11\n",
    "    return\n",
    "fun()\n",
    "print('x is currently', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun1(x):\n",
    "    def fun2():\n",
    "        nonlocal x\n",
    "        print('non local x is', x)\n",
    "        x = -25\n",
    "    return fun2()\n",
    "x = 3\n",
    "fun1(x)\n",
    "print('x is currently', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
